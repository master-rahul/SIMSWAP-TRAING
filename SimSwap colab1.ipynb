{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimSwap colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_gtFoV8BuRx"
      },
      "source": [
        "This is a simple example of SimSwap on processing video with multiple faces. You can change the codes for inference based on our other scripts for image or single face swapping.\n",
        "\n",
        "Code path: https://github.com/neuralchen/SimSwap\n",
        "\n",
        "Paper path: https://arxiv.org/pdf/2106.06340v1.pdf or https://dl.acm.org/doi/10.1145/3394171.3413630"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y1RfpzsCAl9",
        "outputId": "f05c963b-f52c-4908-911f-8598e9e8a6a7"
      },
      "source": [
        "## make sure you are using a runtime with GPU\n",
        "## you can check at Runtime/Change runtime type in the top bar.\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 22 15:34:51 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qzzx2UpDkqw"
      },
      "source": [
        "## Installation\n",
        "\n",
        "All file changes made by this notebook are temporary.\n",
        "You can try to mount your own google drive to store files if you want.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA_4CeWZCHLP",
        "outputId": "01a18fe8-dce0-488e-a60b-d7441ec195e4"
      },
      "source": [
        "!git clone https://github.com/neuralchen/SimSwap\n",
        "!cd SimSwap && git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SimSwap'...\n",
            "remote: Enumerating objects: 1141, done.\u001b[K\n",
            "remote: Counting objects: 100% (1141/1141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (557/557), done.\u001b[K\n",
            "remote: Total 1141 (delta 603), reused 1015 (delta 566), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1141/1141), 211.46 MiB | 37.97 MiB/s, done.\n",
            "Resolving deltas: 100% (603/603), done.\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5K4au_UCkKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a88319-0e42-4df6-d693-54136bb701a6"
      },
      "source": [
        "!pip install insightface==0.2.1 onnxruntime moviepy\n",
        "!pip install googledrivedownloader\n",
        "!pip install imageio==2.4.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface==0.2.1\n",
            "  Downloading insightface-0.2.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (1.26.4)\n",
            "Collecting onnx (from insightface==0.2.1)\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (3.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (10.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (1.5.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (0.24.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from insightface==0.2.1) (1.13)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.35.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->insightface==0.2.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->insightface==0.2.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->insightface==0.2.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->insightface==0.2.1) (2024.8.30)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.2.1) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.2.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.2.1) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.2.1) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.2.1) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface==0.2.1) (2.8.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface==0.2.1) (3.4.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface==0.2.1) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface==0.2.1) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface==0.2.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface==0.2.1) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->insightface==0.2.1) (1.16.0)\n",
            "Downloading insightface-0.2.1-py2.py3-none-any.whl (24 kB)\n",
            "Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.2.1 onnx-1.17.0 onnxruntime-1.19.2\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.10/dist-packages (0.4)\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (10.4.0)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303884 sha256=515ff3e05417e2d39157f2f6cd1f0403273eaa52a17e629c1375ba3d693988bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/5d/ce/bdbdb04744dac03906336eb0d01ff1e222061d3419c55c55f9\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.35.1\n",
            "    Uninstalling imageio-2.35.1:\n",
            "      Successfully uninstalled imageio-2.35.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "moviepy 1.0.3 requires imageio<3.0,>=2.5; python_version >= \"3.4\", but you have imageio 2.4.1 which is incompatible.\n",
            "scikit-image 0.24.0 requires imageio>=2.33, but you have imageio 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed imageio-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ7ZoIbLFCye",
        "outputId": "40993768-fb71-4732-cd42-2fbe97bb205f"
      },
      "source": [
        "import os\n",
        "os.chdir(\"SimSwap\")\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " cog.yaml\t       options\t\t\t test_video_swap_multispecific.py\n",
            " crop_224\t       output\t\t\t test_video_swapsingle.py\n",
            " data\t\t       parsing_model\t\t test_video_swapspecific.py\n",
            " demo_file\t       pg_modules\t\t test_wholeimage_swapmulti.py\n",
            " docs\t\t       predict.py\t\t test_wholeimage_swap_multispecific.py\n",
            " download-weights.sh   README.md\t\t test_wholeimage_swapsingle.py\n",
            " insightface_func     'SimSwap colab.ipynb'\t test_wholeimage_swapspecific.py\n",
            " LICENSE\t       simswaplogo\t\t train.ipynb\n",
            " models\t\t       test_one_image.py\t train.py\n",
            " MultiSpecific.ipynb   test_video_swapmulti.py\t util\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLti1J0pEFjJ",
        "outputId": "febd8194-b9b2-4f0b-9a2f-2b1fa6188fe0"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader\n",
        "\n",
        "### it seems that google drive link may not be permenant, you can find this ID from our open url.\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1TLNdIufzwesDbyr_nVTR7Zrx9oRHLM_N',\n",
        "#                                     dest_path='./arcface_model/arcface_checkpoint.tar')\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1PXkRiBUYbu1xWpQyDEJvGKeqqUFthJcI',\n",
        "#                                     dest_path='./checkpoints.zip')\n",
        "\n",
        "!wget -P ./arcface_model https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
        "!wget https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
        "!unzip ./checkpoints.zip  -d ./checkpoints\n",
        "!wget -P ./parsing_model/checkpoint https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-22 15:36:05--  https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/f01468b3-446b-4867-8c78-6d496183f9e6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241022%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241022T153605Z&X-Amz-Expires=300&X-Amz-Signature=7bb40b38c651b0c776cc7ed7c36b89eb20f8f7c54bb28b1f8e361a98e47e59b1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-10-22 15:36:05--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/f01468b3-446b-4867-8c78-6d496183f9e6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241022%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241022T153605Z&X-Amz-Expires=300&X-Amz-Signature=7bb40b38c651b0c776cc7ed7c36b89eb20f8f7c54bb28b1f8e361a98e47e59b1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209280521 (200M) [application/octet-stream]\n",
            "Saving to: ‘./arcface_model/arcface_checkpoint.tar’\n",
            "\n",
            "arcface_checkpoint. 100%[===================>] 199.58M   120MB/s    in 1.7s    \n",
            "\n",
            "2024-10-22 15:36:07 (120 MB/s) - ‘./arcface_model/arcface_checkpoint.tar’ saved [209280521/209280521]\n",
            "\n",
            "--2024-10-22 15:36:08--  https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241022%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241022T153608Z&X-Amz-Expires=300&X-Amz-Signature=1bd065a87df0a88b060c0fa034532cfe77d2f881b7031211b575eec9b5fa3564&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-10-22 15:36:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241022%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241022T153608Z&X-Amz-Expires=300&X-Amz-Signature=1bd065a87df0a88b060c0fa034532cfe77d2f881b7031211b575eec9b5fa3564&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256461775 (245M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints.zip’\n",
            "\n",
            "checkpoints.zip     100%[===================>] 244.58M   114MB/s    in 2.1s    \n",
            "\n",
            "2024-10-22 15:36:10 (114 MB/s) - ‘checkpoints.zip’ saved [256461775/256461775]\n",
            "\n",
            "Archive:  ./checkpoints.zip\n",
            "   creating: ./checkpoints/people/\n",
            "  inflating: ./checkpoints/people/iter.txt  \n",
            "  inflating: ./checkpoints/people/latest_net_D1.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_D2.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_G.pth  \n",
            "  inflating: ./checkpoints/people/loss_log.txt  \n",
            "  inflating: ./checkpoints/people/opt.txt  \n",
            "   creating: ./checkpoints/people/web/\n",
            "   creating: ./checkpoints/people/web/images/\n",
            "--2024-10-22 15:36:14--  https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241022%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241022T153614Z&X-Amz-Expires=300&X-Amz-Signature=4f4e43aaea73c77e46ad03062450576b01b6d8e60e219acf99eb8d92551362b4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-10-22 15:36:14--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241022%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241022T153614Z&X-Amz-Expires=300&X-Amz-Signature=4f4e43aaea73c77e46ad03062450576b01b6d8e60e219acf99eb8d92551362b4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘./parsing_model/checkpoint/79999_iter.pth’\n",
            "\n",
            "79999_iter.pth      100%[===================>]  50.82M   113MB/s    in 0.4s    \n",
            "\n",
            "2024-10-22 15:36:15 (113 MB/s) - ‘./parsing_model/checkpoint/79999_iter.pth’ saved [53289463/53289463]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSRnK5V4HI-k",
        "outputId": "cb0f4eac-b2a3-4ce2-b2f5-c66949305c48"
      },
      "source": [
        "## You can upload filed manually\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "### Now onedrive file can be downloaded in Colab directly!\n",
        "### If the link blow is not permanent, you can just download it from the\n",
        "### open url(can be found at [our repo]/doc/guidance/preparation.md) and copy the assigned download link here.\n",
        "### many thanks to woctezuma for this very useful help\n",
        "!wget --no-check-certificate \"https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\" -O antelope.zip\n",
        "!unzip ./antelope.zip -d ./insightface_func/models/\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-22 15:36:32--  https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\n",
            "Resolving sh23tw.dm.files.1drv.com (sh23tw.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to sh23tw.dm.files.1drv.com (sh23tw.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248024513 (237M) [application/zip]\n",
            "Saving to: ‘antelope.zip’\n",
            "\n",
            "antelope.zip        100%[===================>] 236.53M  33.8MB/s    in 7.1s    \n",
            "\n",
            "2024-10-22 15:36:40 (33.3 MB/s) - ‘antelope.zip’ saved [248024513/248024513]\n",
            "\n",
            "Archive:  ./antelope.zip\n",
            "   creating: ./insightface_func/models/antelope/\n",
            "  inflating: ./insightface_func/models/antelope/glintr100.onnx  \n",
            "  inflating: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsGmIMxLVxyO"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfSsND36EMvn",
        "outputId": "ac2f9621-268b-424f-ebeb-c9a1b563dff1"
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "import fractions\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from models.models import create_model\n",
        "from options.test_options import TestOptions\n",
        "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
        "from util.videoswap import video_swap\n",
        "from util.add_watermark import watermark_image"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxSbZ2EDNDlf"
      },
      "source": [
        "transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "transformer_Arcface = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "detransformer = transforms.Compose([\n",
        "        transforms.Normalize([0, 0, 0], [1/0.229, 1/0.224, 1/0.225]),\n",
        "        transforms.Normalize([-0.485, -0.456, -0.406], [1, 1, 1])\n",
        "    ])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wwJOwR9LNKRz",
        "outputId": "5cf3cad1-175c-45f6-d7d1-4217b0bf98c0"
      },
      "source": [
        "opt = TestOptions()\n",
        "opt.initialize()\n",
        "opt.parser.add_argument('-f') ## dummy arg to avoid bug\n",
        "opt = opt.parse()\n",
        "opt.pic_a_path = './demo_file/Iron_man.jpg' ## or replace it with image from your own google drive\n",
        "opt.video_path = './demo_file/multi_people_1080p.mp4' ## or replace it with video from your own google drive\n",
        "opt.output_path = './output/demo.mp4'\n",
        "opt.temp_path = './tmp'\n",
        "opt.Arc_path = './arcface_model/arcface_checkpoint.tar'\n",
        "opt.isTrain = False\n",
        "opt.use_mask = True  ## new feature up-to-date\n",
        "\n",
        "crop_size = opt.crop_size\n",
        "\n",
        "torch.nn.Module.dump_patches = True\n",
        "model = create_model(opt)\n",
        "model.eval()\n",
        "\n",
        "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
        "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
        "\n",
        "with torch.no_grad():\n",
        "    pic_a = opt.pic_a_path\n",
        "    # img_a = Image.open(pic_a).convert('RGB')\n",
        "    img_a_whole = cv2.imread(pic_a)\n",
        "    img_a_align_crop, _ = app.get(img_a_whole,crop_size)\n",
        "    img_a_align_crop_pil = Image.fromarray(cv2.cvtColor(img_a_align_crop[0],cv2.COLOR_BGR2RGB))\n",
        "    img_a = transformer_Arcface(img_a_align_crop_pil)\n",
        "    img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
        "\n",
        "    # convert numpy to tensor\n",
        "    img_id = img_id.cuda()\n",
        "\n",
        "    #create latent id\n",
        "    img_id_downsample = F.interpolate(img_id, size=(112,112))\n",
        "    latend_id = model.netArc(img_id_downsample)\n",
        "    latend_id = latend_id.detach().to('cpu')\n",
        "    latend_id = latend_id/np.linalg.norm(latend_id,axis=1,keepdims=True)\n",
        "    latend_id = latend_id.to('cuda')\n",
        "\n",
        "    video_swap(opt.video_path, latend_id, model, app, opt.output_path, temp_results_dir=opt.temp_path, use_mask=opt.use_mask)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 512\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "f: /root/.local/share/jupyter/runtime/kernel-4c630e14-2ecc-40d6-9a70-3b7f7388e1a3.json\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/\n",
            "phase: test\n",
            "pic_a_path: G:/swap_data/ID/elon-musk-hero-image.jpeg\n",
            "pic_b_path: ./demo_file/multi_people.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: False\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/content/SimSwap/models/fs_model.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  netArc_checkpoint = torch.load(netArc_checkpoint, map_location=torch.device(\"cpu\"))\n",
            "\n",
            "WARNING:py.warnings:/content/SimSwap/models/base_model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  network.load_state_dict(torch.load(save_path))\n",
            "\n",
            "WARNING:py.warnings:/content/SimSwap/models/base_model.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  pretrained_dict = torch.load(save_path)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained network G has fewer layers; The following are not initialized:\n",
            "['down0', 'first_layer', 'last_layer', 'up0']\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "(142, 366, 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 260MB/s]\n",
            "WARNING:py.warnings:/content/SimSwap/util/videoswap.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(save_pth))\n",
            "\n",
            "  0%|          | 0/594 [00:00<?, ?it/s]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "  0%|          | 0/594 [00:02<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-46a887c84c9b>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mlatend_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatend_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mvideo_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatend_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_results_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/SimSwap/util/videoswap.py\u001b[0m in \u001b[0;36mvideo_swap\u001b[0;34m(video_path, id_vetor, swap_model, detect_model, save_path, temp_results_dir, crop_size, no_simswaplogo, use_mask)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 reverse2wholeimage(frame_align_crop_tenor_list,swap_result_list, frame_mat_list, crop_size, frame, logoclass,\\\n\u001b[0m\u001b[1;32m     97\u001b[0m                     os.path.join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)),no_simswaplogo,pasring_model =net,use_mask=use_mask, norm = spNorm)\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SimSwap/util/reverse2original.py\u001b[0m in \u001b[0;36mreverse2wholeimage\u001b[0;34m(b_align_crop_tenor_list, swaped_imgs, mats, crop_size, oriimg, logoclass, save_path, no_simswaplogo, pasring_model, norm, use_mask)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mtarget_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mtarget_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'testing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rty2GsyZZrI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe08c70-ac77-4c95-e3fe-c73a98202e31"
      },
      "source": [
        "!python test_one_image.py --name people --Arc_path arcface_model/arcface_checkpoint.tar --pic_a_path crop_224/1_source.jpg --pic_b_path crop_224/2.jpg --output_path output/\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 512\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: output/\n",
            "phase: test\n",
            "pic_a_path: crop_224/1_source.jpg\n",
            "pic_b_path: crop_224/2.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: False\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "OUTPUT BEGIN :: \n",
            "**************\n",
            "Namespace(name='people', gpu_ids=[0], checkpoints_dir='./checkpoints', norm='batch', use_dropout=False, data_type=32, verbose=True, fp16=False, local_rank=0, isTrain=False, batchSize=8, loadSize=1024, fineSize=512, label_nc=0, input_nc=3, output_nc=3, dataroot='./datasets/cityscapes/', resize_or_crop='scale_width', serial_batches=False, no_flip=False, nThreads=2, max_dataset_size=inf, display_winsize=512, tf_log=False, netG='global', latent_size=512, ngf=64, n_downsample_global=3, n_blocks_global=6, n_blocks_local=3, n_local_enhancers=1, niter_fix_global=0, no_instance=False, instance_feat=False, label_feat=False, feat_num=3, load_features=False, n_downsample_E=4, nef=16, n_clusters=10, image_size=224, norm_G='spectralspadesyncbatch3x3', semantic_nc=3, ntest=inf, results_dir='./results/', aspect_ratio=1.0, phase='test', which_epoch='latest', how_many=50, cluster_path='features_clustered_010.npy', use_encoded_image=False, export_onnx=None, engine=None, onnx=None, Arc_path='arcface_model/arcface_checkpoint.tar', pic_a_path='crop_224/1_source.jpg', pic_b_path='crop_224/2.jpg', pic_specific_path='./crop_224/zrf.jpg', multisepcific_dir='./demo_file/multispecific', video_path='G:/swap_data/video/HSB_Demo_Trim.mp4', temp_path='./temp_results', output_path='output/', id_thres=0.03, no_simswaplogo=False, use_mask=False, crop_size=512)\n",
            "**************\n",
            "True\n",
            "OUTPUT END :: \n",
            "Pretrained network G has fewer layers; The following are not initialized:\n",
            "['down0', 'first_layer', 'last_layer', 'up0']\n",
            "model [fsModel] was created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt =0"
      ],
      "metadata": {
        "id": "fAhM7wfR4jbM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "76EF1MS853Bi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cD0s0IVx52Dc"
      }
    }
  ]
}